@misc{ghoul_2022_virtual,
  author = {Ghoul, Oussama El and Othman, Achraf},
  month = {03},
  pages = {1269–1274},
  title = {Virtual reality for educating Sign Language using signing avatar: The future of creative learning for deaf students},
  doi = {10.1109/EDUCON52537.2022.9766692},
  url = {https://ieeexplore.ieee.org/document/9766692},
  urldate = {2023-05-10},
  year = {2022},
  organization = {IEEE Xplore},
  abstract = {In the United States, the National Institute on Deafness and Other Communication Disorders estimates that 90 or more deaf children have hearing parents. Communication is one of the first aspects of family life impacted by having a deaf child. The hearing parents of deaf children and teachers often have difficulty communicating with their deaf children and need to interact with them using sign language. Deaf children and hearing parents still face many challenges in learning sign languages despite technological advances such as mobile apps, desktop and web applications, and new instructional materials and methods. In Qatar, 13.7 of the persons with disabilities have some difficulties, many challenges, or cannot hear totally, highlighting the need to include and foster ICT accessibility of deaf and hard of hearing persons in education. In this paper, we presented a new approach based on virtual reality (VR) to teach the basics of Qatari Sign Language (QSL) for teachers and parents, which can be extended to beginner interpreters for sign language. We experimented on 52 participants from specialized primary schools and higher institutes to teach them new signs in QSL (Arabic Sign Language). Virtual reality presented an innovative way for fast education through impact assessment conduct before and after the training sessions.},
  series = {},
  keywords = {avatars , computer aided instruction , gesture recognition , handicapped aids , interactive systems , teaching , virtual reality, Sign language}
}

@article{quandt_2020_teaching,
  author = {Quandt, Lorna},
  month = {10},
  title = {Teaching ASL Signs using Signing Avatars and Immersive Learning in Virtual Reality},
  doi = {10.1145/3373625.3418042},
  urldate = {2023-05-10},
  year = {2020},
  journal = {The 22nd International ACM SIGACCESS Conference on Computers and Accessibility},
  abstract = {We present here a new system, in which signing avatars (computer-animated virtual humans built from motion capture recordings) teach introductory American Sign Language (ASL) in an immersive virtual environment. The system is called Signing Avatars & Immersive Learning (SAIL). The signifcant contributions of this work are 1) the use of signing avatars, built from state-of-the-art motion capture recordings of a native signer; 2) the integration with LEAP gesture tracking hardware, allowing the user to see his or her own movements within the virtual environment; 3) the development of appropriate introductory ASL vocabulary, delivered in semi-interactive lessons; and 4) the 3D environment in which a user accesses the system.},
  series = {},
  keywords = {sign language, virtual humans, ASL, virtual reality, education}
}

@article{galvnruiz_2020_perspective,
  author = {Galván-Ruiz, Jesús and Travieso-González, Carlos M. and Tejera-Fettmilch, Acaymo and Pinan-Roescher, Alejandro and Esteban-Hernández, Luis and Domínguez-Quintana, Luis},
  month = {06},
  pages = {3571},
  title = {Perspective and Evolution of Gesture Recognition for Sign Language: A Review},
  doi = {10.3390/s20123571},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7349703/},
  urldate = {2023-05-10},
  volume = {20},
  year = {2020},
  journal = {Sensors (Basel, Switzerland)},
  abstract = {This review analyses the different gesture recognition systems through a timeline, showing the different types of technology, and specifying which are the most important features and their achieved recognition rates. At the end of the review, Leap Motion sensor possibilities are described in detail, in order to consider its application on the field of sign language. This device has many positive characteristics that make it a good option for sign language. One of the most important conclusions is the ability of the Leap Motion sensor to provide 3D information from the hands for due identification.},
  series = {},
  keywords = {gesture recognition; algorithms; Leap Motion; pattern recognition; EMG; RFID; gloves; Wi-Fi, gesture recognition, sign language}
}

@article{mahmoud_2020_does,
  author = {Mahmoud, Khadija and Harris, Isaac and Yassin, Husam and Hurkxkens, Thomas J. and Matar, Omar K. and Bhatia, Nitesh and Kalkanis, Irene},
  pages = {480-498},
  title = {Does Immersive VR Increase Learning Gain When Compared to a Non-immersive VR Learning Experience?},
  doi = {10.1007/978-3-030-50506-6_33},
  urldate = {2023-05-10},
  year = {2020},
  journal = {Learning and Collaboration Technologies. Human and Technology Ecosystems},
  abstract = {Currently, computer assisted learning and multimedia form a key part of teaching. Interactivity and feedback are valuable in promoting active as opposed to passive learning. The study is conducted as an assessment of the impact of immersive VR on learning gain compared with a non-immersive video capture of VR, with a primary research question focusing on exploring learning gain and a secondary question exploring user experience, whereby understanding this is paramount to recognizing how to achieve a complete and effective learning experience. The study found immersive VR to significantly increase learning gain whilst two key measures of reported experience; enjoyment and concentration, also appeared significantly higher for the immersive VR learners. The study suggests extensive avenues for further research in this growing field, recognizing the need to appeal to a variety of students’ learning preferences. For educators, the relevance of self-directed and student-centered learning to enable active learning in the immersive tool is highlighted. Findings of such VR-based studies can be applied across several disciplines, including medical education; providing opportunity for users to learn without real-world consequences of error such as in surgical intervention.},
  series = {},
  keywords = {Virtual reality, Education, Medicine, Self-directed learning, Active learning}
}

@article{meier_2021_demonstrating,
  author = {Meier, Manuel and Streli, Paul and Fender, Andreas and Holz, Christian},
  month = {03},
  title = {Demonstrating the Use of Rapid Touch Interaction in Virtual Reality for Prolonged Interaction in Productivity Scenarios},
  doi = {10.1109/vrw52623.2021.00263},
  urldate = {2023-05-10},
  year = {2021},
  journal = {2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
  abstract = {Current camera-based VR headsets support free-hand mid-air inter-action or physical hand-held controllers for input, which can lead to fatigue during use, as users lack support for their arms and hands between interactions. In our demonstration, we showcase a novel approach to bring quick touch interaction to Virtual Reality, illustrating the beneficial use of rapid tapping, typing, and surface gestures for ongoing interaction in Virtual Reality, particularly in the con-text of content creation and productivity scenarios. The productivity scenarios that become possible using our approach are therefore reminiscent of apps that exist on today's phones and tablets. To reliably make touch interaction work in VR, we use a wrist-worn prototype to complement the optical hand tracking from VR headsets with inertial sensing to detect touch events on surfaces. Our prototype band TapID integrates a pair of inertial sensors in a flexible strap, from whose signals TapID reliably detects surface touch events and identifies the finger used for touch. This event detection is then fused with the optically tracked hand poses to trigger input in VR. Our demonstration comprises a series of VR applications, including UI control in word processors, web browsers, and document editors.},
  series = {},
  keywords = {cameras , gesture recognition , human computer interaction , optical tracking , touch sensitive screens , user interfaces , virtual reality , wearable computers}
}

@article{onishi_2019_a,
  author = {Onishi, Atsuki and Nishiguchi, Satoshi and Mizutani, Yasuharu and Hashimoto, Wataru},
  month = {10},
  title = {A Study of Usability Improvement in Immersive VR Programming Environment},
  doi = {10.1109/cw.2019.00073},
  urldate = {2023-05-10},
  year = {2019},
  journal = {2019 International Conference on Cyberworlds (CW)},
  abstract = {Visual programming environments such as Scratch have been proposed for beginners. In those environments, programming is possible by arranging function blocks expressed on two dimensions. In order to improve the browsability of many blocks, an environment for programming by arranging functional blocks with hand gesture interaction in immersive VR space has been proposed. However, operation error by Leap Motion when setting the value and the usability of the environment was not good due to the error of estimation of hand gesture. In this study, we propose an operation method using VR controller for programming in an immersive VR environment and compare the results. We will incorporate these results into future development.},
  series = {},
  keywords = {gesture recognition , virtual reality , visual programming}
}

@article{vergara2016enhancing,
  title = {Enhancing the teaching/learning of materials mechanical characterization by using virtual reality},
  author = {Vergara, D and Rubio, MP and Prieto, F and Lorenzo, M},
  journal = {J. Mater. Educ},
  volume = {38},
  number = {3-4},
  pages = {63--74},
  year = {2016},
  abstract = {The use of virtual laboratories (VLs) in teaching/learning is increasing in the last decade. As each virtual tool, these educational resources must be constantly updated in order not to become obsolete and, so, to keep student motivation. Thus, an up-to-date and sophisticated virtual 3D environment - fitted as a serious game - is presented in this paper, which shows the operation of a universal testing machine in an interactive way. This 3D-VL motivates students to study the mechanical characterization of materials. According to survey results, students demand not only the combined use of both real and virtual laboratories for their experimental classes, but also they request virtual environments designed in 3D. Thus, 3D interactive VLs become really attractive for teaching, since their use is highly encouraging.},
  doi = {https://doi.org/10.1061/(ASCE)EI.1943-5541.0000311},
  series = {},
  keywords = {virtual laboratory, 3D virtual worlds, virtual reality, mechanical characterization., teaching}
}

@article{vergara_2019_meaningful,
  author = {Vergara, Diego and Extremera, Jamil and Rubio, Manuel Pablo and Dávila, Lílian P.},
  month = {10},
  pages = {4625},
  title = {Meaningful Learning Through Virtual Reality Learning Environments: A Case Study in Materials Engineering},
  doi = {10.3390/app9214625},
  volume = {9},
  year = {2019},
  journal = {Applied Sciences},
  abstract = {The use of virtual laboratories (VLs) in teaching/learning is increasing in the last decade. As each virtual tool, these educational resources must be constantly updated in order not to become obsolete and, so, to keep student motivation. Thus, an up-to-date and sophisticated virtual 3D environment - fitted as a serious game - is presented in this paper, which shows the operation of a universal testing machine in an interactive way. This 3D-VL motivates students to study the mechanical characterization of materials. According to survey results, students demand not only the combined use of both real and virtual laboratories for their experimental classes, but also they request virtual environments designed in 3D. Thus, 3D interactive VLs become really attractive for teaching, since their use is highly encouraging.},
  series = {},
  keywords = {virtual laboratory; virtual reality learning environment; meaningful learning; design; materials science and engineering., Virtual reality, teaching, teaching}
}

@article{gul_2020_twoway,
  author = {Gul, Areesha and Zehra, Batool and Shah, Sadia and Javed, Nazish and Saleem, Muhammad Imran},
  month = {02},
  title = {Two-way Smart Communication System for Deaf & Dumb and Normal People},
  doi = {10.1109/icisct49550.2020.9080028},
  urldate = {2023-05-10},
  year = {2020},
  journal = {2020 International Conference on Information Science and Communication Technology (ICISCT)},
  abstract = {With regard to Deaf & Dumb individuals, communication with others is a way longer struggle for them. They are unable to speak with traditional individuals properly. They face difficulties in finding jobs and living a traditional life like others. In this paper, We are introducing a two-way smart communication system for Deaf & Dumb and also for Normal people. The system consists of two main parts: The first part is for Deaf & Dumb person to convey their messages to a normal person by using our hardware system and the second one is for a normal person who can also respond them easily without learning a sign language by using our Android Application. This ensures a two-way smart communication system and will make life less demanding for them. The overall accuracy of the system is 92.5, with both the hands involved.},
  series = {},
  keywords = {two-way smart communication system , normal person , hardware system , deaf & dumb individuals , Android application, Sign language}
}

@article{oudah_2020_hand,
  author = {Oudah, Munir and Al-Naji, Ali and Chahl, Javaan},
  month = {07},
  pages = {73},
  title = {Hand Gesture Recognition Based on Computer Vision: A Review of Techniques},
  doi = {10.3390/jimaging6080073},
  volume = {6},
  year = {2020},
  journal = {Journal of Imaging},
  abstract = {The increasing dissemination of virtual reality learning environments (VRLEs) compels the elucidation of how these didactic tools can improve their effectiveness at the formative level. The motivation generated in students by a VRLE is revealed as a key factor in achieving meaningful learning, but such a motivation by itself alone does not guarantee the long-term retention of knowledge. To identify the necessary characteristics of a VRLE to achieve an appropriate level of meaningful learning, this paper compares a set of VRLEs created in previous years with a group of recently developed VRLEs, after being used by engineering students. A description of the design process of the both VRLEs groups is included in this paper. Most significantly, analysis of the response of a total of 103 students in a specific survey reveals how a step-by-step protocol system helped improve students' knowledge and retention after one year of using a VRLE. Thus, this study not only demonstrates the importance of using modern development engines when creating or updating a VRLE to achieve student motivation, but also justifies in many cases the use of a step-by-step protocol as a method to improve the long-term retention of knowledge.},
  series = {},
  keywords = {hand gesture; hand posture; computer vision; human–computer interaction (HCI), Gesture recognition}
}

@article{Beck2016Visual,
  abstract = {Bibiographic data such as collections of scientific articles and citation networks have been studied extensively in information visualization and visual analytics research. Powerful systems have been built to support various types of bibliographic analysis, but they require some training and cannot be used to disseminate the insights gained. In contrast, we focused on developing a more accessible visual analytics system, called SurVis, that is ready to disseminate a carefully surveyed literature collection. The authors of a survey may use our Web-based system to structure and analyze their literature database. Later, readers of the survey can obtain an overview, quickly retrieve specific publications, and reproduce or extend the original bibliographic analysis. Our system employs a set of selectors that enable users to filter and browse the literature collection as well as to control interactive visualizations. The versatile selector concept includes selectors for textual search, filtering by keywords and meta-information, selection and clustering of similar publications, and following citation links. Agreement to the selector is represented by word-sized sparkline visualizations seamlessly integrated into the user interface. Based on an analysis of the analytical reasoning process, we derived requirements for the system. We developed the system in a formative way involving other researchers writing literature surveys. A questionnaire study with 14 visual analytics experts confirms that SurVis meets the initially formulated requirements.},
  author = {Beck, Fabian and Koch, Sebastian and Weiskopf, Daniel},
  doi = {10.1109/TVCG.2015.2467757},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  keywords = {type:system, visual_analytics, sparklines, information_retrieval, clustering, literature_browser},
  number = {01},
  publisher = {IEEE},
  series = {TVCG},
  title = {Visual Analysis and Dissemination of Scientific Literature Collections with {SurVis}},
  url = {http://www.visus.uni-stuttgart.de/uploads/tx_vispublications/vast15-survis.pdf},
  volume = {22},
  year = {2016}
}

